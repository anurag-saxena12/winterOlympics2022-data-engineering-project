# Data Sprint: Beijing 2022

## Introduction
Welcome to the "Olympic Data Sprint," a personal end-to-end data engineering project aimed at gaining hands-on experience with various Azure services. By utilizing Azure Data Factory for ingestion, Data Lake Gen2 for storage, Databricks for transformations, Synapse Analytics for simple data visualizations, and Azure Key Vault for security, we will explore the full ETL process while deepening our familiarity with these powerful tools. Join me as and uncover valuable insights from the 2022 Beijing Olympic data! Please note, that more projects will be coming soon, including an end-to-end ML pipeline.

_Note: Before diving into this document, know that not all of these services were needed to execute the project. I could have done this project all on Synpase Analytics or even Data Factory, but I wanted to explore the different tools and how to connect various services together to form a complete pipeline._

## Architecture
![Architecture Diagram](/assets/OlympicProject.drawio.png)

## Technology Used
- Programming Language: Python (PySpark Library)
- Scripting Language: SQL
- Microsoft Azure Cloud Platform
  - Data Factory
  - Data Lake Gen2
  - Databricks
  - Key Vault
  - Synpase Analytics

## Dataset Used
Original Data Source (Kaggle): https://www.kaggle.com/datasets/arjunprasadsarkhel/2022-winter-olympics-beijing

GitHub Link: https://github.com/anurag-saxena12/winterOlympics2022-data-engineering-project/tree/main/data

## Data Model
![Data Model](/assets/data_model.png)









